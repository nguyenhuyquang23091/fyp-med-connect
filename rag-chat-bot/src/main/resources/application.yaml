server:
  port: 8082
  servlet:
    context-path: /chatbot

spring:
  datasource:
      url: ${POSTGRES_URL:}
      username: ${POSTGRES_USERNAME:}
      password: ${POSTGRES_PASSWORD:}
  jpa:
      hibernate:
        ddl-auto: update
      show-sql: true
  ai:
    ollama:
      base-url: ${BASE_URL:}
      init:
        pull-model-strategy: always
        timeout: 5m
        max-retries: 5
      chat:
        options:
          model: ${MODEL:}
          temperature: 0.2  # Low temperature for more focused, consistent responses
          num-predict: 512  # Max tokens limit - controls response length (Ollama parameter)
          top-p: 0.9
      embedding:
        options:
          model: ${MODEL:}
    vectorstore:
      qdrant:
        host: localhost
        port: 6334
        collection-name: ${COLLECTION_NAME:}
        use-tls: false
    chat:
      memory:
        repository:
          jdbc:
            initialize-schema: always

logging:
  level:
    org:
      springframework:
        ai: DEBUG
        ai.chat.client.advisor: DEBUG
        ai.vectorstore: DEBUG
        ai.vectorstore.qdrant: DEBUG
        ai.ollama: DEBUG
    io:
      qdrant: DEBUG
    com.fyp.rag_chat_bot: DEBUG


management:
  endpoints:
    web:
      exposure:
        include: info, health, prometheus, metrics

